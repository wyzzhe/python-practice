# AI

## Qwen3-32B-FP8

- 最大token数: 40960 tokens

- 服务器: 24G * 4 = 96G

- 显存占用: 

60W /  150W 

21452MiB /  24564MiB

- 单次提问占用: 

你好	53%	100W

金卡会员有哪些权益	91%	150W

有日料吗	 100%	150W

- 显存占用解释：

模型加载到显存时，占用显存主要是模型的静态参数(权重、偏置、固定计算图结构)，<u>不受并发数影响</u>

并发访问模型时，只需要只读参数，共享显存

并发访问时，推理过程的临时数据包括：

​	1 输入的数据的预处理 单卡24G显存剩余3.11G 上下文限制40k (有日料吗)实际输入19k

​	2 推理时的中间计算张量(激活值、特征图)

​	3 框架的临时缓存(批处理的缓冲区)



# 技术指标

## RPM

每分钟最多请求数

`doubao-pro-32k` RPM=15,000

## TPM

每分钟最多token数(输入+输出)

`doubao-pro-32k` TPM=1,200,000

##  并发量

100万会员交互式Agent

访问量3%->3万会员咨询

高峰时段4小时处理80%咨询->24000/4=6000每小时咨询

峰值时段处理量为其他时段2倍->6000/6*2=2000每十分钟咨询

每个问题处理时间5秒->2000/12 (60s / 5s)=167每秒并发量

## 显卡

### 算力

FLOPS 浮点运算/秒

OPS 任意运算/秒

A10 在FP

### 英伟达H100

显存：80GB

价格：200,000

### 英伟达A10

显存：24GB

算力精度：FP16/BF16/TF32/INT8/INT4 (只是显卡算力精度FP16，和模型压缩精度FP8无关)

单卡算力：A10 FP16 峰值 125 TFLOPS（=125×10¹² 次浮点运算/秒）

张量并行算力：4张A10 张量并行 **350TFLOPS**(TB 浮点运算/秒) 张量并行保留70%效果

token计算速度：

​	FP16算力, 32B模型(每个参数都被使用), 512token数

​	2 x (32 x 10^9) x 512 = 33 TFOPS (完成 512 token 所以需要的总运算量)

​	理论首token时延 33 TFOPS / 350 TFLOPS = 0.09 ms(算力时延) x 700(网络时延经验系数) -> 60ms(网络时延)

首token时延公式：

​	A10*4	350    TFLOPS -> 0.09ms -> 60ms

​	any卡	 1400  TFLOPS -> 0.02ms -> 15ms

价格：20,000

数量：4

总显存：96

## 模型技术指标

### 参数量 32B

320亿参数量

32×10⁹ 个权重 在1字节下占用显存32GB(32×10⁹ Byte)

> 32GB 指 把模型所有参数全部放到显存里占用的显存大小, 和并发量无关

FP8 位宽 8bit 字节 1 byte

FP16 位宽16 bit 字节 2 byte

7B / 14B / 32B / 70B / 110B

参数量越大，模型能力大幅提升，消耗显存越大

### 量化技术 FP8

优点：节省显存

缺点：效果变差

FP8 FP16 

位宽越大，模型能力越好，消耗显存越大

## 硬件成本

预算：20w

## 技术指标提示词

我的机器型号：
4张英伟达A10显卡

我的模型：
Qwen3-32B-FP8
